{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b8553a-84e1-4420-9b1f-20b8c033a7d8",
   "metadata": {},
   "source": [
    "### Построение вопрос-ответных систем (ВОС) RAG-архитектуры (Retrieval Augmented Generation) на базе фреймворка Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a765174-6f43-47b5-b1eb-e6b926689ccf",
   "metadata": {},
   "source": [
    "- Данный Jupyter ноутбук - это адаптированная под YandexGPT версия оригинального langchain ноутбука по [ссылке](https://python.langchain.com/docs/expression_language/cookbook/retrieval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ee6e4c-c274-49fb-ba57-1bbb6ab3b56f",
   "metadata": {},
   "source": [
    "- Давайте рассмотрим добавление шага извлечения к LLM-промпту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c301c000-794b-44a5-82c7-19049c0a4104",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:40:22.363799Z",
     "iopub.status.busy": "2024-03-24T10:40:22.362785Z",
     "iopub.status.idle": "2024-03-24T10:40:49.565074Z",
     "shell.execute_reply": "2024-03-24T10:40:49.564323Z",
     "shell.execute_reply.started": "2024-03-24T10:40:22.363758Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade --quiet  langchain yandexcloud==0.255.0 faiss-cpu yandex-chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc15aa47-b15c-4c1e-9d5f-b743109520d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:43:28.226073Z",
     "iopub.status.busy": "2024-03-24T10:43:28.225300Z",
     "iopub.status.idle": "2024-03-24T10:43:28.240014Z",
     "shell.execute_reply": "2024-03-24T10:43:28.239207Z",
     "shell.execute_reply.started": "2024-03-24T10:43:28.226033Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "from langchain_community.chat_models import ChatYandexGPT\n",
    "# from langchain_community.llms import YandexGPT\n",
    "# from langchain_community.embeddings.yandex import YandexGPTEmbeddings\n",
    "from yandex_chain import YandexEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013184de-cbde-4eb8-8601-8d0e85b69d41",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-24T10:32:54.503864039Z",
     "iopub.status.idle": "2024-03-24T10:32:54.543633035Z",
     "shell.execute_reply": "2024-03-24T10:32:54.503743053Z"
    }
   },
   "source": [
    "##### Получаем IAM-токен для работы с YandexGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d3afaa1-69b3-406a-8fe8-e9848afc6f0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:34:30.280358Z",
     "iopub.status.busy": "2024-03-24T10:34:30.279781Z",
     "iopub.status.idle": "2024-03-24T10:34:31.068524Z",
     "shell.execute_reply": "2024-03-24T10:34:31.067776Z",
     "shell.execute_reply.started": "2024-03-24T10:34:30.280315Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import jwt\n",
    "import requests\n",
    "import os\n",
    "service_account_id = os.environ[\"SA_ID\"]\n",
    "key_id = os.environ[\"KEY_ID\"]\n",
    "folder_id = os.environ[\"YC_FOLDER_ID\"]\n",
    "private_key = \"-----BEGIN PRIVATE KEY-----\\nДобаляете здесь ваш приватный ключ\\n-----END PRIVATE KEY-----\\n\"\n",
    "# Получаем IAM-токен\n",
    "now = int(time.time())\n",
    "payload = {\n",
    "        'aud': 'https://iam.api.cloud.yandex.net/iam/v1/tokens',\n",
    "        'iss': service_account_id,\n",
    "        'iat': now,\n",
    "        'exp': now + 360}\n",
    "# Формирование JWT\n",
    "encoded_token = jwt.encode(\n",
    "    payload,\n",
    "    private_key,\n",
    "    algorithm='PS256',\n",
    "    headers={'kid': key_id})\n",
    "url = 'https://iam.api.cloud.yandex.net/iam/v1/tokens'\n",
    "x = requests.post(url,  \n",
    "                  headers={'Content-Type': 'application/json'},\n",
    "                  json = {'jwt': encoded_token}).json()\n",
    "token = x['iamToken']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e11d04f3-d24d-46e0-af66-a985c38d73d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:46:47.422492Z",
     "iopub.status.busy": "2024-03-24T10:46:47.421672Z",
     "iopub.status.idle": "2024-03-24T10:46:47.439286Z",
     "shell.execute_reply": "2024-03-24T10:46:47.438658Z",
     "shell.execute_reply.started": "2024-03-24T10:46:47.422447Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "yagpt_embeddings = YandexEmbeddings(folder_id=folder_id, iam_token = token)\n",
    "yagpt_embeddings.sleep_interval = 0.1 #текущее ограничение эмбеддера 10 RPS, делаем задержку 1/10 секунды, чтобы не выйти за это ограничение\n",
    "\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "yagpt_model = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f534f2-12c5-4702-acfd-7c5bbf7c1bcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:49:41.104325Z",
     "iopub.status.busy": "2024-03-24T10:49:41.103667Z",
     "iopub.status.idle": "2024-03-24T10:49:41.336135Z",
     "shell.execute_reply": "2024-03-24T10:49:41.335319Z",
     "shell.execute_reply.started": "2024-03-24T10:49:41.104293Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "vectorstore = FAISS.from_texts(\n",
    "    [\"Марк работал в супермаркете\"], embedding=yagpt_embeddings\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "template = \"\"\"Отвечай на вопрос, основываясь только на следующем контексте:\n",
    "{context}\n",
    "\n",
    "Вопрос: {question}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "model = yagpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59bb24a2-79c7-47dd-b63c-2b943ccc3321",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:49:42.445184Z",
     "iopub.status.busy": "2024-03-24T10:49:42.444461Z",
     "iopub.status.idle": "2024-03-24T10:49:42.460657Z",
     "shell.execute_reply": "2024-03-24T10:49:42.459860Z",
     "shell.execute_reply.started": "2024-03-24T10:49:42.445140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8161dbde-9a1e-4ae3-918a-5aca1c67385f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:49:50.414735Z",
     "iopub.status.busy": "2024-03-24T10:49:50.413892Z",
     "iopub.status.idle": "2024-03-24T10:49:51.680776Z",
     "shell.execute_reply": "2024-03-24T10:49:51.680088Z",
     "shell.execute_reply.started": "2024-03-24T10:49:50.414691Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'В супермаркете.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"Где работал Марк?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "88fd85d6-fe48-44fe-a1c0-cffb2301ef21",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:50:36.594373Z",
     "iopub.status.busy": "2024-03-24T10:50:36.593654Z",
     "iopub.status.idle": "2024-03-24T10:50:36.606403Z",
     "shell.execute_reply": "2024-03-24T10:50:36.605618Z",
     "shell.execute_reply.started": "2024-03-24T10:50:36.594335Z"
    }
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Отвечай на вопрос, основываясь только на следующем контексте:\n",
    "{context}\n",
    "\n",
    "Вопрос: {question}\n",
    "\n",
    "Отвечай на следующем языке: {language}\n",
    "\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "\n",
    "chain = (\n",
    "    {\n",
    "        \"context\": itemgetter(\"question\") | retriever,\n",
    "        \"question\": itemgetter(\"question\"),\n",
    "        \"language\": itemgetter(\"language\"),\n",
    "    }\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07bfcbf3-419f-4577-bede-33e801682fdd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:50:54.978102Z",
     "iopub.status.busy": "2024-03-24T10:50:54.977368Z",
     "iopub.status.idle": "2024-03-24T10:50:55.868393Z",
     "shell.execute_reply": "2024-03-24T10:50:55.867764Z",
     "shell.execute_reply.started": "2024-03-24T10:50:54.978065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mark worked at the supermarket.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"question\": \"где работал марк\", \"language\": \"english\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b94f7c79-9368-464b-841c-a20c5ecd3b41",
   "metadata": {},
   "source": [
    "### Conversational Retrieval Chain - вопрос-ответная система с учетом истории общения"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bcc8da1-b190-4017-8243-765e53c23f92",
   "metadata": {},
   "source": [
    "- Мы можем легко добавить исторический контекст беседы в общение. В первую очередь это означает добавление в chat_message_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ca8f378d-b859-4c76-aa36-1385a4189f7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T10:52:52.387297Z",
     "iopub.status.busy": "2024-03-24T10:52:52.386404Z",
     "iopub.status.idle": "2024-03-24T10:52:52.400269Z",
     "shell.execute_reply": "2024-03-24T10:52:52.399501Z",
     "shell.execute_reply.started": "2024-03-24T10:52:52.387249Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, get_buffer_string\n",
    "from langchain_core.prompts import format_document\n",
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0b45c9b-6de8-4b57-a354-562d3fa49d2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:38.599048Z",
     "iopub.status.busy": "2024-03-24T11:02:38.598309Z",
     "iopub.status.idle": "2024-03-24T11:02:38.610437Z",
     "shell.execute_reply": "2024-03-24T11:02:38.609666Z",
     "shell.execute_reply.started": "2024-03-24T11:02:38.599005Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Учитывая историю общения и текущий вопрос, составь из всего этого отдельный общий вопрос на русском языке.\n",
    "\n",
    "История общения:\n",
    "{chat_history}\n",
    "Текущий вопрос: {question}\n",
    "Отдельный общий вопрос:\"\"\"\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d7aa5631-6844-4e23-8bbd-48aea6a400c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:40.643487Z",
     "iopub.status.busy": "2024-03-24T11:02:40.642774Z",
     "iopub.status.idle": "2024-03-24T11:02:40.655218Z",
     "shell.execute_reply": "2024-03-24T11:02:40.654404Z",
     "shell.execute_reply.started": "2024-03-24T11:02:40.643443Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "template = \"\"\"Отвечай на вопрос, основываясь только на следующем контексте:\n",
    "{context}\n",
    "\n",
    "Вопрос: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0b0ff264-e51b-4ef7-84b5-a2adb5d67cc9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:42.447408Z",
     "iopub.status.busy": "2024-03-24T11:02:42.446305Z",
     "iopub.status.idle": "2024-03-24T11:02:42.458923Z",
     "shell.execute_reply": "2024-03-24T11:02:42.458354Z",
     "shell.execute_reply.started": "2024-03-24T11:02:42.447364Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DEFAULT_DOCUMENT_PROMPT = PromptTemplate.from_template(template=\"{page_content}\")\n",
    "\n",
    "\n",
    "def _combine_documents(\n",
    "    docs, document_prompt=DEFAULT_DOCUMENT_PROMPT, document_separator=\"\\n\\n\"\n",
    "):\n",
    "    doc_strings = [format_document(doc, document_prompt) for doc in docs]\n",
    "    return document_separator.join(doc_strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32247d39-89b5-4794-85c5-34e408f4b6c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:44.511644Z",
     "iopub.status.busy": "2024-03-24T11:02:44.510838Z",
     "iopub.status.idle": "2024-03-24T11:02:44.521880Z",
     "shell.execute_reply": "2024-03-24T11:02:44.521321Z",
     "shell.execute_reply.started": "2024-03-24T11:02:44.511615Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "yagpt_model = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "_inputs = RunnableParallel(\n",
    "    standalone_question=RunnablePassthrough.assign(\n",
    "        chat_history=lambda x: get_buffer_string(x[\"chat_history\"])\n",
    "    )\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | yagpt_model\n",
    "    | StrOutputParser(),\n",
    ")\n",
    "_context = {\n",
    "    \"context\": itemgetter(\"standalone_question\") | retriever | _combine_documents,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "conversational_qa_chain = _inputs | _context | ANSWER_PROMPT | yagpt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "358b51fd-4124-4136-9ed4-aa204f72262f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:02:46.533433Z",
     "iopub.status.busy": "2024-03-24T11:02:46.532621Z",
     "iopub.status.idle": "2024-03-24T11:02:48.200430Z",
     "shell.execute_reply": "2024-03-24T11:02:48.199775Z",
     "shell.execute_reply.started": "2024-03-24T11:02:46.533396Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Марк работал в супермаркете.')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"где работал Марк?\",\n",
    "        \"chat_history\": [],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c2785f78-6c90-4b00-a7b9-a0985c1842a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:03:05.569586Z",
     "iopub.status.busy": "2024-03-24T11:03:05.568660Z",
     "iopub.status.idle": "2024-03-24T11:03:07.174428Z",
     "shell.execute_reply": "2024-03-24T11:03:07.173663Z",
     "shell.execute_reply.started": "2024-03-24T11:03:05.569549Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='В супермаркете.')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversational_qa_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"где он работал?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"кто написал этот ноутбук?\"),\n",
    "            AIMessage(content=\"Марк\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c5ec3c-e844-4be8-9b16-aabad7d03e64",
   "metadata": {},
   "source": [
    "### Добавим к поддержке истории общения также ссылки на источники информации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2231d5be-b699-40dd-81e1-769f0d58be5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:04:31.096439Z",
     "iopub.status.busy": "2024-03-24T11:04:31.095576Z",
     "iopub.status.idle": "2024-03-24T11:04:31.922347Z",
     "shell.execute_reply": "2024-03-24T11:04:31.921590Z",
     "shell.execute_reply.started": "2024-03-24T11:04:31.096398Z"
    }
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "363ae91e-2638-4a85-a910-6ec1cb3abeb7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:04:40.297825Z",
     "iopub.status.busy": "2024-03-24T11:04:40.297124Z",
     "iopub.status.idle": "2024-03-24T11:04:40.307374Z",
     "shell.execute_reply": "2024-03-24T11:04:40.306543Z",
     "shell.execute_reply.started": "2024-03-24T11:04:40.297789Z"
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationBufferMemory(\n",
    "    return_messages=True, output_key=\"answer\", input_key=\"question\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0355ff24-8b9b-42ee-8809-9043927a7eb4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:09:20.381954Z",
     "iopub.status.busy": "2024-03-24T11:09:20.380993Z",
     "iopub.status.idle": "2024-03-24T11:09:20.397297Z",
     "shell.execute_reply": "2024-03-24T11:09:20.396503Z",
     "shell.execute_reply.started": "2024-03-24T11:09:20.381911Z"
    }
   },
   "outputs": [],
   "source": [
    "# Сначала мы добавляем шаг для загрузки памяти\n",
    "# Поэтому добавляем ключ \"memory\" во входящий объект\n",
    "loaded_memory = RunnablePassthrough.assign(\n",
    "    chat_history=RunnableLambda(memory.load_memory_variables) | itemgetter(\"history\"),\n",
    ")\n",
    "\n",
    "# выбираем какую yandexgpt модель будем использовать, и выставляем ее temperature = 0\n",
    "# model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt-lite/latest\"\n",
    "model_uri = \"gpt://\"+str(folder_id)+\"/yandexgpt/latest\"\n",
    "yagpt_model = ChatYandexGPT(iam_token = token, model_uri=model_uri, temperature = 0)\n",
    "\n",
    "# Теперь определяем standalone_question (композитный вопрос, который учитывает историю общения)\n",
    "standalone_question = {\n",
    "    \"standalone_question\": {\n",
    "        \"question\": lambda x: x[\"question\"],\n",
    "        \"chat_history\": lambda x: get_buffer_string(x[\"chat_history\"]),\n",
    "    }\n",
    "    | CONDENSE_QUESTION_PROMPT\n",
    "    | yagpt_model\n",
    "    | StrOutputParser(),\n",
    "}\n",
    "# Теперь извлекаем нужные документы\n",
    "retrieved_documents = {\n",
    "    \"docs\": itemgetter(\"standalone_question\") | retriever,\n",
    "    \"question\": lambda x: x[\"standalone_question\"],\n",
    "}\n",
    "# Конструируем вводные для финального промпта\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: _combine_documents(x[\"docs\"]),\n",
    "    \"question\": itemgetter(\"question\"),\n",
    "}\n",
    "# Теперь запускаем выдачу ответов\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | yagpt_model,\n",
    "    \"docs\": itemgetter(\"docs\"),\n",
    "}\n",
    "# И собираем все вместе!\n",
    "final_chain = loaded_memory | standalone_question | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "10a4b421-e527-4d46-bf42-8b24bcd7f212",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:09:58.042334Z",
     "iopub.status.busy": "2024-03-24T11:09:58.041524Z",
     "iopub.status.idle": "2024-03-24T11:09:59.788435Z",
     "shell.execute_reply": "2024-03-24T11:09:59.787648Z",
     "shell.execute_reply.started": "2024-03-24T11:09:58.042293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': AIMessage(content='Марк работал в супермаркете.'),\n",
       " 'docs': [Document(page_content='Марк работал в супермаркете')]}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"где работал Марк?\"}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0ec09e74-5309-4734-be0a-c052f54a6a2f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:12:20.212559Z",
     "iopub.status.busy": "2024-03-24T11:12:20.211688Z",
     "iopub.status.idle": "2024-03-24T11:12:20.227539Z",
     "shell.execute_reply": "2024-03-24T11:12:20.226906Z",
     "shell.execute_reply.started": "2024-03-24T11:12:20.212512Z"
    }
   },
   "outputs": [],
   "source": [
    "# Обратите внимание, что память не сохраняется автоматически\n",
    "# В будущем это будет улучшено\n",
    "# А пока вам нужно сохранять данные в память самостоятельно\n",
    "memory.save_context(inputs, {\"answer\": result[\"answer\"].content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ef2608e-9dcd-465d-a437-a34cba03bce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:12:45.413732Z",
     "iopub.status.busy": "2024-03-24T11:12:45.412918Z",
     "iopub.status.idle": "2024-03-24T11:12:45.435974Z",
     "shell.execute_reply": "2024-03-24T11:12:45.435160Z",
     "shell.execute_reply.started": "2024-03-24T11:12:45.413677Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': [HumanMessage(content='где работал Марк?'),\n",
       "  AIMessage(content='Марк работал в супермаркете.')]}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b8a0deae-a696-461b-9443-79bb7d00aede",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-24T11:13:17.207211Z",
     "iopub.status.busy": "2024-03-24T11:13:17.206246Z",
     "iopub.status.idle": "2024-03-24T11:13:18.734890Z",
     "shell.execute_reply": "2024-03-24T11:13:18.734220Z",
     "shell.execute_reply.started": "2024-03-24T11:13:17.207169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': AIMessage(content='В супермаркете.'),\n",
       " 'docs': [Document(page_content='Марк работал в супермаркете')]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = {\"question\": \"Но где же он на самом деле работал?\"}\n",
    "result = final_chain.invoke(inputs)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b135c2-09bc-4c78-862f-c354e22f80fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataSphere Kernel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
